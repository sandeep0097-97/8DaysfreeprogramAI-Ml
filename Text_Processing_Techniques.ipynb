{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Common Text Processing Techniques\n",
        "#Letâ€™s explore some essential text processing techniques and how they contribute to the preparation of textual data.\n",
        "\n",
        "#Tokenization\n",
        "#Tokenization is the process of splitting text into smaller units called tokens, which can be words, sentences, or subwords."
      ],
      "metadata": {
        "id": "0MRspWJcacAW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35o-LS3EaD8h",
        "outputId": "87351517-11a7-42be-ce2d-3aea44619f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'is', 'fascinating', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Ensure you have the necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"Natural Language Processing is fascinating.\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lowercasing\n",
        "#Converting all characters in the text to lowercase to ensure uniformity."
      ],
      "metadata": {
        "id": "1MZiqdF0dcf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lowercase_text = text.lower()\n",
        "print(\"Lowercase Text:\", lowercase_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz56usnsakpq",
        "outputId": "687bb4dc-e790-431a-bb04-b1489b114cf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercase Text: natural language processing is fascinating.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Removing Punctuation\n",
        "#Removing punctuation marks from the text"
      ],
      "metadata": {
        "id": "xPLtQA6pdr4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "text_no_punctuation = text.translate(str.maketrans('', '', string.punctuation))\n",
        "print(\"Text without Punctuation:\", text_no_punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhqrD0pFdjsq",
        "outputId": "74b411ea-4056-41cb-ca90-3692a22919a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text without Punctuation: Natural Language Processing is fascinating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Removing Special Characters\n",
        "#Removing special characters that are not needed for analysis."
      ],
      "metadata": {
        "id": "Vh8dtbCPdztZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text_no_special_chars = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "print(\"Text without Special Characters:\", text_no_special_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb8L6cAbdwTp",
        "outputId": "f78c98be-0a35-4788-8125-d66db583d3f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text without Special Characters: Natural Language Processing is fascinating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Removing Numbers\n",
        "#Removing numerical values from the text."
      ],
      "metadata": {
        "id": "9wPVz7a7d6l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_no_numbers = re.sub(r'\\d+', '', text)\n",
        "print(\"Text without Numbers:\", text_no_numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlcQcXHed3rL",
        "outputId": "9ad370e6-6962-4501-956a-3beb851dd034"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text without Numbers: Natural Language Processing is fascinating.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o0JluT7yd-fK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}